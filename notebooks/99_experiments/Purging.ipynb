{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51857336",
   "metadata": {},
   "source": [
    "## Purging\n",
    "\n",
    "In time series problems, using a KFold or StratifiedKFold can lead to data leakage if the training observations are temporally close to the validation observations.\n",
    "This causes the model to indirectly see future information, inflating the metrics.\n",
    "\n",
    "**Purging** is a validation technique that:\n",
    "\n",
    "1. Splits the data by *groups* (in this case, dates or time indices).\n",
    "2. Inserts a time gap between the training and validation sets (`group_gap`) to prevent information leakage.\n",
    "3. Allows you to limit the maximum size of the training or test groups (`max_train_group_size`, `max_test_group_size`).\n",
    "\n",
    "**Advantage**: Reproduces a real *out-of-sample* training and validation scenario, preventing the model from being trained with data very close to the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29facb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../scripts\"))\n",
    "from sklearn.model_selection import GridSearchCV, BaseCrossValidator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, brier_score_loss\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model_utils import rolling_test, optimize_threshold\n",
    "from preprocessing import feature_engineering, analyze_features\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42b9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PurgedGroupTimeSeriesSplit(BaseCrossValidator):\n",
    "    def __init__(self, n_splits=5, group_gap=1, max_train_group_size=None, max_test_group_size=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.group_gap = group_gap\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\"The 'groups' parameter should not be None\")\n",
    "\n",
    "        unique_groups = np.unique(groups)\n",
    "        n_groups = len(unique_groups)\n",
    "\n",
    "        if self.n_splits > n_groups:\n",
    "            raise ValueError(\"Number of splits must be less than or equal to the number of groups\")\n",
    "\n",
    "        group_test_size = self.max_test_group_size or (n_groups // self.n_splits)\n",
    "        group_test_starts = range(n_groups - self.n_splits * group_test_size, n_groups, group_test_size)\n",
    "\n",
    "        for test_start in group_test_starts:\n",
    "            test_end = test_start + group_test_size\n",
    "            train_end = test_start - self.group_gap\n",
    "            train_start = 0 if self.max_train_group_size is None else max(0, train_end - self.max_train_group_size)\n",
    "\n",
    "            train_groups = unique_groups[train_start:train_end]\n",
    "            test_groups = unique_groups[test_start:test_end]\n",
    "\n",
    "            train_indices = np.where(np.isin(groups, train_groups))[0]\n",
    "            test_indices = np.where(np.isin(groups, test_groups))[0]\n",
    "            yield train_indices, test_indices\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0251b6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator PowerTransformer from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator QuantileTransformer from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator _SigmoidCalibration from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CalibratedClassifierCV from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('../../data/X.csv', index_col='date', parse_dates=True)\n",
    "y = pd.read_csv('../../data/y.csv', index_col='date', parse_dates=True)\n",
    "groups = X.index\n",
    "pipeline = joblib.load(\"../../models/final_mlp_pipeline.joblib\")\n",
    "model = pipeline.named_steps['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f694a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 150\n",
    "\n",
    "X_train, y_train = X.iloc[:split], y.iloc[:split]\n",
    "X_test, y_test = X.iloc[split:], y.iloc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12c7ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    (\"power\", PowerTransformer(), X_train.columns),\n",
    "    (\"quantile\", QuantileTransformer(output_distribution='normal'), X_train.columns)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f53c6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e68cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "purged_split = PurgedGroupTimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    group_gap=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d87e1c",
   "metadata": {},
   "source": [
    "In our case:\n",
    "\n",
    "- **Groups**: Each observation date.\n",
    "- **Time gap**: 5 steps (`group_gap=5`), which prevents observations close in time to the validation set from entering the training.\n",
    "- **Number of splits**: 5.\n",
    "- **Model evaluated**: The final pipeline (`MLPClassifier` + `PowerTransformer` + `QuantileTransformer`), pre-calibrated and with an adjusted threshold.\n",
    "- **Metrics**: Accuracy, ROC AUC, F1, and Brier Score in train and test.\n",
    "\n",
    "This allows us to verify whether our usual validation method (`rolling test`) was introducing information leakage. If the metrics are similar, we can conclude that there was no significant leakage, and that is the main purpose of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ac573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (483). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (95). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (191). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (287). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "/home/pogger/miniconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2785: UserWarning: n_quantiles (1000) is greater than the total number of samples (383). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy Scores: [0.5548654244306418, 0.6736842105263158, 0.4397905759162304, 0.47038327526132406, 0.5091383812010444]\n",
      "Test Accuracy Scores: [0.6354166666666666, 0.375, 0.4791666666666667, 0.46875, 0.5208333333333334]\n",
      "Average Train Accuracy Score: 0.5295723734671112\n",
      "Average Test Accuracy Score: 0.4958333333333333\n",
      "Train Roc_auc Scores: [0.5975056689342404, 0.7793040293040293, 0.39284145805884935, 0.38663809894818857, 0.45904371584699455]\n",
      "Test Roc_auc Scores: [0.6633928571428571, 0.42569930069930073, 0.4575163398692811, 0.42683456361267913, 0.41521739130434787]\n",
      "Average Train Roc_auc Score: 0.5230665942184605\n",
      "Average Test Roc_auc Score: 0.4777320905256932\n",
      "Train F1 Scores: [0.6861313868613139, 0.7801418439716312, 0.5367965367965368, 0.6122448979591837, 0.6747404844290658]\n",
      "Test F1 Scores: [0.7445255474452555, 0.5238095238095238, 0.6031746031746031, 0.5321100917431193, 0.684931506849315]\n",
      "Average Train F1 Score: 0.6580110300035462\n",
      "Average Test F1 Score: 0.6177102546043634\n",
      "Train Brier Scores: [0.2469184606414967, 0.20997348249779446, 0.25757895935497227, 0.2550813283305361, 0.2501158090562446]\n",
      "Test Brier Scores: [0.24205533189361073, 0.28632672402009357, 0.2500437809183205, 0.252747108983054, 0.25068250411392795]\n",
      "Average Train Brier Score: 0.24393360797620883\n",
      "Average Test Brier Score: 0.2563710899858013\n"
     ]
    }
   ],
   "source": [
    "train_scores = {'accuracy': [], 'roc_auc': [], 'f1': [], 'brier': []}\n",
    "test_scores = {'accuracy': [], 'roc_auc': [], 'f1': [], 'brier': []}\n",
    "\n",
    "\n",
    "for train_idx, test_idx in purged_split.split(X, y, groups=groups):\n",
    "\n",
    "    X_train_split, X_test_split = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_split, y_test_split = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    pipeline.fit(X_train_split, y_train_split.values.ravel())\n",
    "    \n",
    "    y_train_pred = pipeline.predict(X_train_split)\n",
    "    y_train_proba = pipeline.predict_proba(X_train_split)[:, 1]\n",
    "    y_test_pred = pipeline.predict(X_test_split)\n",
    "    y_test_proba = pipeline.predict_proba(X_test_split)[:, 1]\n",
    "    \n",
    "    train_scores['accuracy'].append(accuracy_score(y_train_split, y_train_pred))\n",
    "    train_scores['roc_auc'].append(roc_auc_score(y_train_split, y_train_proba))\n",
    "    train_scores['f1'].append(f1_score(y_train_split, y_train_pred))\n",
    "    train_scores['brier'].append(brier_score_loss(y_train_split, y_train_proba))\n",
    "    \n",
    "    test_scores['accuracy'].append(accuracy_score(y_test_split, y_test_pred))\n",
    "    test_scores['roc_auc'].append(roc_auc_score(y_test_split, y_test_proba))\n",
    "    test_scores['f1'].append(f1_score(y_test_split, y_test_pred))\n",
    "    test_scores['brier'].append(brier_score_loss(y_test_split, y_test_proba))\n",
    "\n",
    "for metric in train_scores.keys():\n",
    "    print(f\"Train {metric.capitalize()} Scores:\", train_scores[metric])\n",
    "    print(f\"Test {metric.capitalize()} Scores:\", test_scores[metric])\n",
    "    print(f\"Average Train {metric.capitalize()} Score:\", np.mean(train_scores[metric]))\n",
    "    print(f\"Average Test {metric.capitalize()} Score:\", np.mean(test_scores[metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab30a776",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Averages in tests with PGTSS:\n",
    "\n",
    "- **Accuracy**: ~0.496\n",
    "- **ROC AUC**: ~0.478\n",
    "- **F1**: ~0.618\n",
    "- **Brier Score**: ~0.256\n",
    "\n",
    "Compared to the previous rolling test, the metrics are **very similar**, indicating that our original method was not introducing relevant information leakage.\n",
    "\n",
    "Furthermore, the fact that PGTSS does not improve the metrics is expected:\n",
    "- Its goal is to detect leakage, not optimize performance.\n",
    "- If the metrics had dropped drastically, it would indicate that the rolling test was overestimating performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5aaff",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Using the PurgedGroupTimeSeriesSplit confirms that our original pipeline and validation method (rolling test) were not contaminated by future data.\n",
    "This gives us confidence that the holdout metrics reflect realistic performance.\n",
    "\n",
    "**Role in the project**:\n",
    "- Remains as an internal verification tool.\n",
    "- Does not replace the rolling test as the primary validation method, but serves as an additional check against data leakage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
